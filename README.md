
# ğŸ… Tokyo Olympic Data of 2021 â€“ End-to-End Azure Data Engineering Project

![Azure](https://img.shields.io/badge/Platform-Microsoft%20Azure-blue)
![GitHub](https://img.shields.io/badge/Repo-Version--Controlled-lightgrey)
![Pipeline](https://img.shields.io/badge/Data-Pipeline-green)

## ğŸ“Œ Project Overview

This project demonstrates an **end-to-end Azure Data Engineering pipeline** built on the **Tokyo Olympic dataset**.
It covers **data ingestion, transformation, storage, querying, and automation** using Azure cloud services.

ğŸ”— **GitHub Repository:** [Tokyo-OlympicData-Azure-Dataengineering-Project](https://github.com/darshant15/Tokyo-OlympicData-Azure-Dataengineering-Project.git)

---

## ğŸ¯ Objectives

* Design and implement a **cloud-based ETL pipeline** for Olympic data.
* Automate **data ingestion, transformation, and analytics**.
* Showcase integration of multiple **Azure services** with version control on GitHub.

---

## ğŸ—ï¸ Architecture Workflow

1. **Data Ingestion** â€“ CSV files ingested from GitHub using **Azure Data Factory (ADF)**.
2. **Data Lake Storage** â€“ Raw and processed data stored in **Azure Data Lake Storage Gen2** (separate containers for `raw-data` and `transformed-data`).
3. **Data Processing** â€“ Used **Azure Databricks (Spark)** for:

   * Data cleaning
   * Deduplication
   * Feature engineering
   * Transformations
4. **Data Warehouse** â€“ Loaded transformed datasets into **Azure Synapse Analytics (Lake Database)** for robust SQL querying and insights.
5. **Automation & Monitoring** â€“ Implemented **ADF scheduling and monitoring** to ensure reliable and timely pipeline refresh.
6. **Version Control** â€“ All Databricks notebooks and ADF workflows cloned into **GitHub** for collaboration and reproducibility.

---

## âš™ï¸ Tech Stack & Tools

* **Azure Data Factory (ADF)** â€“ Data ingestion, orchestration, scheduling
* **Azure Data Lake Storage Gen2 (ADLS)** â€“ Raw and curated data storage
* **Azure Databricks (Apache Spark)** â€“ Data cleaning, transformations, feature engineering
* **Azure Synapse Analytics** â€“ SQL querying, analytics-ready storage
* **GitHub** â€“ Version control and project showcase

---

## ğŸ“Š Key Insights (Examples)

* Medal distribution across countries and sports
* Athlete performance analysis
* Historical trends of Olympic participation
* Country-wise comparisons

---

## ğŸš€ How to Use

1. Clone the repository:

   ```bash
   git clone https://github.com/darshant15/Tokyo-OlympicData-Azure-Dataengineering-Project.git
   ```
2. Import the notebooks into **Azure Databricks**.
3. Configure **ADF pipelines** with proper linked services for GitHub and ADLS.
4. Run pipeline to ingest â†’ transform â†’ load data.
5. Query insights using **Synapse Analytics**.

---
## ğŸ“Œ Author

ğŸ‘¤ **Darshan T**

* ğŸ”— [GitHub Profile](https://github.com/darshant15)

---

âœ¨ This project highlights **real-world Azure Data Engineering skills** â€“ from ingestion to automation â€“ and can be extended with **Power BI dashboards** for visualization if it's required.

---

## Architect Diagram
<a href ="[https://github.com/darshant15/Data-Analysis-Dashboard-On-Swiggy-Instamart-Sales-Report-/commit/03f450ebe733933eb48e4b187ce8549c047f3f4e">**Architect-**(https://github.com/darshant15/Tokyo-OlympicData-Azure-Dataengineering-Project/blob/main/Architect-of-project.jpeg)</a>


