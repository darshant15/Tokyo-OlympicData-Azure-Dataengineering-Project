
# ğŸ… Tokyo Olympic Data of 2021 â€“ End-to-End Azure Data Engineering Project

![Azure](https://img.shields.io/badge/Platform-Microsoft%20Azure-blue)
![GitHub](https://img.shields.io/badge/Repo-Version--Controlled-lightgrey)
![Pipeline](https://img.shields.io/badge/Data-Pipeline-green)

## ğŸ“Œ Project Overview

This project demonstrates an **end-to-end Azure Data Engineering pipeline** built on the **Tokyo Olympic dataset**.
It covers **data ingestion, transformation, storage, querying, and automation** using Azure cloud services.

---
## ğŸš€ Project Highlights

- **Automated Ingestion**: Pipelines in **Azure Data Factory (ADF)** ingest raw Tokyo Olympics datasets (athletes, medals, teams, entries, etc.) into **Azure Data Lake Storage Gen2**.  
- **Data Lake Architecture**: 
  - **Raw zone** â†’ Ingested unprocessed datasets  
  - **Curated zone** â†’ Cleaned, transformed Parquet/Delta data optimized for analytics  
- **Secure Pipeline Management**: Store credentials and secrets in **Azure Key Vault** for secure operations.  
- **Scalable Data Processing**: Use **Azure Databricks (PySpark)** for cleaning, deduplication, joins, and aggregations.  
- **Analytics-Ready Storage**: Query curated datasets using **Azure Synapse Analytics** (SQL serverless/dedicated pool).  
- **BI & Dashboards**: Build **Power BI** dashboards to visualize insights like medal tallies, gender participation, athlete demographics, and country performance by the data analysis(Report) using data given after ELT from data engineer .

--- 

ğŸ”— **GitHub Repository:** [Tokyo-OlympicData-Azure-Dataengineering-Project](https://github.com/darshant15/Tokyo-OlympicData-Azure-Dataengineering-Project.git)

---
## Architect Diagram

![Architect](https://github.com/darshant15/Tokyo-OlympicData-Azure-Dataengineering-Project/blob/main/Architect-of-project.jpeg)

---

## ğŸ¯ Objectives

* Design and implement a **cloud-based ETL pipeline** for Olympic data.
* Automate **data ingestion, transformation, and analytics**.
* Showcase integration of multiple **Azure services** with version control on GitHub.

---

## ğŸ—ï¸ Architecture Workflow

1. **Data Ingestion** â€“ CSV files ingested from GitHub using **Azure Data Factory (ADF)**.
2. **Data Lake Storage** â€“ Raw and processed data stored in **Azure Data Lake Storage Gen2** (separate containers for `raw-data` and `transformed-data`).
3. **Data Processing** â€“ Used **Azure Databricks (Spark)** for:

   * Data cleaning
   * Deduplication
   * Feature engineering
   * Transformations
4. **Data Warehouse** â€“ Loaded transformed datasets into **Azure Synapse Analytics (Lake Database)** for robust SQL querying and insights.
5. **Automation & Monitoring** â€“ Implemented **ADF scheduling and monitoring** to ensure reliable and timely pipeline refresh.
6. **Version Control** â€“ All Databricks notebooks and ADF workflows cloned into **GitHub** for collaboration and reproducibility.

---

## âš™ï¸ Tech Stack & Tools

* **Azure Data Factory (ADF)** â€“ Data ingestion, orchestration, scheduling
* **Azure Data Lake Storage Gen2 (ADLS)** â€“ Raw and curated data storage
* **Azure Databricks (Apache Spark)** â€“ Data cleaning, transformations, feature engineering
* **Azure Synapse Analytics** â€“ SQL querying, analytics-ready storage
* **GitHub** â€“ Version control and project showcase

---

## ğŸ“Š Key Insights (Examples)

* Medal distribution across countries and sports
* Athlete performance analysis
* Historical trends of Olympic participation
* Country-wise comparisons

---

## ğŸš€ How to Use

1. Clone the repository:

   ```bash
   git clone https://github.com/darshant15/Tokyo-OlympicData-Azure-Dataengineering-Project.git
   ```
2. Import the notebooks into **Azure Databricks**.
3. Configure **ADF pipelines** with proper linked services for GitHub and ADLS.
4. Run pipeline to ingest â†’ transform â†’ load data.
5. Query insights using **Synapse Analytics**.

---

## ğŸ“Œ Author

ğŸ‘¤ **Darshan T**

* ğŸ”— [GitHub Profile](https://github.com/darshant15)

---

âœ¨ This project highlights **real-world Azure Data Engineering skills** â€“ from ingestion to automation â€“ and can be extended with **Power BI dashboards** for visualization if it's required.

---


